{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "max_seq_len = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        pe = torch.zeros(max_seq_len, self.embed_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (2 * i / self.embed_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * (i + 1) / self.embed_dim)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)       # pre-calculate and freeze\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x * math.sqrt(self.embed_dim) + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        # return x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.single_head_dim = self.embed_dim // self.num_heads   # 512 / 8 = 64, every head takes its part of the input\n",
    "        self.query_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)  # a big matrix for the whole input\n",
    "        self.key_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)    # we will split the heads later on\n",
    "        self.value_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.mixer = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Q, K, V shapes are (batch x length x single_head_dim) == (32 x 10 x 64)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.single_head_dim)\n",
    "        # scores shape is (batch x length x length) == (32 x 10 x 10)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == False, -1e9)    # put large negative numbers to positions where mask == False\n",
    "        probs = torch.softmax(scores, dim=-1)                   # transform scores to probabilities (B x L x L)\n",
    "                                                                # for each sample in the batch tell how ith token is important to jth token\n",
    "        return torch.matmul(probs, V)                           # re-weigh values according to the probabilities\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()            # B x L x D\n",
    "        assert self.embed_dim == embed_dim\n",
    "        return x.view(                                          # B x L x H x d\n",
    "            batch_size,\n",
    "            seq_length,\n",
    "            self.num_heads,\n",
    "            self.single_head_dim,\n",
    "        ).transpose(1, 2)                                       # B x H x L x d\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, single_head_dim = x.size()\n",
    "        assert self.num_heads == num_heads\n",
    "        assert self.single_head_dim == single_head_dim\n",
    "        # B x H x L x d   => \n",
    "        # B x L x H x d   =>\n",
    "        # B x L x D\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.query_matrix(Q))\n",
    "        K = self.split_heads(self.key_matrix(K))\n",
    "        V = self.split_heads(self.value_matrix(V))        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        return self.mixer(self.combine_heads(attn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, expansion):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(embed_dim, embed_dim * expansion)\n",
    "        self.fc2 = torch.nn.Linear(embed_dim * expansion, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # expand => non-linearity => shrink\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # (attention => droupout) + residual => norm\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, mask)))\n",
    "        # (MLP => dropout) + residual => norm\n",
    "        return self.norm2(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # self attention (decoder x decoder)\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, tgt_mask)))\n",
    "        # cross attention (decoder x encoder), note that queries are from decoder, keys and values - from encoder\n",
    "        x = self.norm2(x + self.dropout(self.cross_attn(x, encoder_output, encoder_output, src_mask)))\n",
    "        # MLP + dropout + residual + norm\n",
    "        return self.norm3(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        # we could split encoder and decoder embeddings\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.encoder_layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = torch.nn.ModuleList([DecoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.embedding(tgt)))\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):\n",
    "        mask = (src != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = src.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(src.device)\n",
    "        mask = mask & nopeak_mask\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self.generate_mask(src)\n",
    "        embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        for layer in self.layers:\n",
    "            embedded = layer(embedded, mask)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458199\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "all_shakespeare = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\").content.decode()\n",
    "print(len(all_shakespeare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<empty>', '<start>', '<end>', 'H', '\"', 'X', 'n', '|', '.', 'L', '!', '7', '*', 'K', '/', 'E', '4', '5', 'd', '2', ':', 'g', '3', '0', ' ', 'x', 'h', '(', '>', 'o', '9', 'p', '_', 'M', 'i', '@', 'W', \"'\", 'B', 'b', 'e', ']', 'I', '~', 'a', 'F', 'l', 'C', '<', 'Y', 'z', 'j', '\\n', 'm', 'u', '`', 'y', '=', '#', '1', 'O', 'N', ')', 't', 'c', ';', '[', 'T', '}', '%', 'R', 'w', '6', '?', 'G', '-', 'P', 'U', ',', 'q', 's', '8', '&', 'r', 'f', 'Z', 'A', 'D', 'V', 'S', 'J', 'Q', 'k', 'v']\n",
      "94\n",
      "{'<empty>': 0, '<start>': 1, '<end>': 2, 'H': 3, '\"': 4, 'X': 5, 'n': 6, '|': 7, '.': 8, 'L': 9, '!': 10, '7': 11, '*': 12, 'K': 13, '/': 14, 'E': 15, '4': 16, '5': 17, 'd': 18, '2': 19, ':': 20, 'g': 21, '3': 22, '0': 23, ' ': 24, 'x': 25, 'h': 26, '(': 27, '>': 28, 'o': 29, '9': 30, 'p': 31, '_': 32, 'M': 33, 'i': 34, '@': 35, 'W': 36, \"'\": 37, 'B': 38, 'b': 39, 'e': 40, ']': 41, 'I': 42, '~': 43, 'a': 44, 'F': 45, 'l': 46, 'C': 47, '<': 48, 'Y': 49, 'z': 50, 'j': 51, '\\n': 52, 'm': 53, 'u': 54, '`': 55, 'y': 56, '=': 57, '#': 58, '1': 59, 'O': 60, 'N': 61, ')': 62, 't': 63, 'c': 64, ';': 65, '[': 66, 'T': 67, '}': 68, '%': 69, 'R': 70, 'w': 71, '6': 72, '?': 73, 'G': 74, '-': 75, 'P': 76, 'U': 77, ',': 78, 'q': 79, 's': 80, '8': 81, '&': 82, 'r': 83, 'f': 84, 'Z': 85, 'A': 86, 'D': 87, 'V': 88, 'S': 89, 'J': 90, 'Q': 91, 'k': 92, 'v': 93}\n"
     ]
    }
   ],
   "source": [
    "dictionary = [\"<empty>\", \"<start>\", \"<end>\"] + list(set(all_shakespeare))\n",
    "print(dictionary)\n",
    "print(len(dictionary))\n",
    "\n",
    "sym2idx = {s: i for i, s in enumerate(dictionary)}\n",
    "print(sym2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42643\n",
      "If the tagrag people did not clap him and hiss him\n",
      "    according as he pleased and displeased them, as they use to do\n",
      "    the p\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "#data = all_shakespeare.split(\"\\n\\n\")\n",
    "#data = list(filter(lambda x: x and len(x) < max_seq_len, data))\n",
    "data = [all_shakespeare[i:i+max_seq_len-1] for i in range(0, len(all_shakespeare), max_seq_len)]\n",
    "random.shuffle(data)\n",
    "\n",
    "print(len(data))\n",
    "print(data[77])\n",
    "print(len(data[77]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " both together heav'd it up,\n",
      "    We'll both together lift our heads to heaven,\n",
      "    And never more abase our sight so low\n",
      "    As\n",
      "\n",
      "thee.\n",
      "  PRINCESS OF FRANCE. Honey, and milk, and sugar; there is three.\n",
      "  BEROWNE. Nay, then, two treys, an if you grow so nice\n"
     ]
    }
   ],
   "source": [
    "train = [data[i] for i in range(len(data)) if i % 10 != 0]\n",
    "test = [data[i] for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "print(train[-5])\n",
    "print(\"\")\n",
    "print(test[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True, False, False, False],\n",
      "          [ True,  True, False, False],\n",
      "          [ True,  True,  True, False],\n",
      "          [False, False, False, False]]]], device='cuda:0')\n",
      "6360158\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([[1, 2, 3, 0]]).to(device)\n",
    "model = Encoder(len(dictionary), 256, 8, 8, 4, max_seq_len, 0.1).to(device)\n",
    "mask = model.generate_mask(src)\n",
    "print(mask)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate(model, len_limit):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = [\"<start>\"] + list(\"Caesar:\")\n",
    "        while len(result) < len_limit:\n",
    "            x = torch.tensor([[sym2idx[x] for x in result]]).to(device)\n",
    "            y = model(x)\n",
    "            y = y[0][-1].cpu().numpy()\n",
    "            y = np.exp(y)\n",
    "            y /= np.sum(y)\n",
    "            #print(\" \".join(map(lambda t: \"{:.4f}\".format(t), y)) + \"\\n\")\n",
    "            x = dictionary[np.random.choice(y.shape[0], p = y)]\n",
    "            if x in [\"<start>\", \"<end>\", \"<empty>\"]:\n",
    "                break\n",
    "            result.append(x)\n",
    "        return ''.join(result[1:])\n",
    "\n",
    "print(generate(model, max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:09<00:00, 549.39it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1559.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.24995 3.21202\n",
      "Caesar: eeDIOmrmoeo\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 547.98it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1559.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.44881 2.09128\n",
      "Caesar: trars,\n",
      "    The I co I fown omod murs\n",
      "    Greingen of and the you.\n",
      "   MOMERCEPrt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 547.99it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1558.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 2.04469 1.77701\n",
      "Caesar:\n",
      "     By the notilds that the set you kiss;\n",
      "      What is treet he chowse and him. Which hyre datercue;\n",
      "    In make epec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 547.98it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1560.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 1.83493 1.67251\n",
      "Caesar: or to out\n",
      "   teagiaty a of tell my leget, my proved-sow\n",
      "   Way, as madatin inking so horrmain, and but in sin to.\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 548.01it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1560.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 1.79621 1.56203\n",
      "Caesar:\n",
      "  Beliss-leck as I grace; he mask, he'll-by so this aughtess. O, hent, how w\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 548.01it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1559.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 1.64953 1.48926\n",
      "Caesar: Celies four in you wity.\n",
      "  HELEN. Feelles, and birturge\n",
      "   vow to lay with sudy.\n",
      "  YORK. You say are he clain me.\n",
      "  Lar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 548.09it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1559.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 1.55180 1.45478\n",
      "Caesar:\n",
      "       When is clott's mind fory by his liet nand,\n",
      "                    Re-enter whiter princes.\n",
      "  DEDEK EWARDY, mady Du\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 548.13it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1560.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 1.56352 1.39742\n",
      "Caesar: which you?\n",
      "  OTHELLO. Prayines! we promize- on, shring?\n",
      "  OCTHELLO. Well I wild spoke you will for you advage.\n",
      "\n",
      "  Ben. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 548.13it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1560.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 1.47003 1.36951\n",
      "Caesar: John.\n",
      "    This is the fielding, Apiton, cast of his la suffe,\n",
      "    My fronow maters, Allbury, undertergct in consent.\n",
      "  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:10<00:00, 548.13it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1560.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 1.43707 1.35032\n",
      "Caesar: my lord!\n",
      "  Ben. What, came?\n",
      "  To marry that, as the me sender was 'tis court.\n",
      "  W\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def iterate_batches(data, batch_size, device):\n",
    "    x, y, max_len = [], [], 0\n",
    "    for k in tqdm.tqdm(range(len(data))):\n",
    "        item = data[k]\n",
    "        x.append([sym2idx[sym] for sym in [\"<start>\"] + list(item)])\n",
    "        y.append([sym2idx[sym] for sym in list(item) + [\"<end>\"]])\n",
    "        max_len = max(max_len, len(x[-1]))\n",
    "        if len(x) == batch_size or k + 1 == len(data):\n",
    "            for i in range(len(x)):\n",
    "                x[i] = x[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(x[i]))]\n",
    "                y[i] = y[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(y[i]))]\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "            yield x, y\n",
    "            x, y, max_len = [], [], 0\n",
    "        \n",
    "\n",
    "def train_epoch(data, model):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    total_loss, total_count = 0.0, 1e-38\n",
    "    random.shuffle(data)\n",
    "    for inputs, answers in iterate_batches(data, 256, device):\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs.shape)\n",
    "        #print(answers.shape)\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.shape)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        #print(outputs.shape)\n",
    "        #print(\"\")\n",
    "        loss = loss_function(outputs, answers)\n",
    "        total_loss += (loss.item() * inputs.shape[0])\n",
    "        total_count += inputs.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def test_epoch(data, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        total_loss, total_count = 0.0, 1e-38\n",
    "        for inputs, answers in iterate_batches(data, 256, device):\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.transpose(1, 2)\n",
    "            loss = loss_function(outputs, answers)\n",
    "            total_loss += (loss.item() * inputs.shape[0])\n",
    "            total_count += inputs.shape[0]\n",
    "        return total_loss / total_count\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for i in range(10):\n",
    "    train_loss = train_epoch(train, model)\n",
    "    test_loss = test_epoch(test, model)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Epoch {} loss: {:.5f} {:.5f}\".format(i, train_loss, test_loss))\n",
    "    print(generate(model, max_seq_len))\n",
    "    print(\"\")\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
