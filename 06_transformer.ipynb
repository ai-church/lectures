{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "max_seq_len = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        pe = torch.zeros(max_seq_len, self.embed_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (2 * i / self.embed_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * (i + 1) / self.embed_dim)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)       # pre-calculate and freeze\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x * math.sqrt(self.embed_dim) + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        # return x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.single_head_dim = self.embed_dim // self.num_heads   # 512 / 8 = 64, every head takes its part of the input\n",
    "        self.query_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)  # a big matrix for the whole input\n",
    "        self.key_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)    # we will split the heads later on\n",
    "        self.value_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.mixer = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Q, K, V shapes are (batch x length x single_head_dim) == (32 x 10 x 64)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.single_head_dim)\n",
    "        # scores shape is (batch x length x length) == (32 x 10 x 10)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == False, -1e9)    # put large negative numbers to positions where mask == False\n",
    "        probs = torch.softmax(scores, dim=-1)                   # transform scores to probabilities (B x L x L)\n",
    "                                                                # for each sample in the batch tell how ith token is important to jth token\n",
    "        return torch.matmul(probs, V)                           # re-weigh values according to the probabilities\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()            # B x L x D\n",
    "        assert self.embed_dim == embed_dim\n",
    "        return x.view(                                          # B x L x H x d\n",
    "            batch_size,\n",
    "            seq_length,\n",
    "            self.num_heads,\n",
    "            self.single_head_dim,\n",
    "        ).transpose(1, 2)                                       # B x H x L x d\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, single_head_dim = x.size()\n",
    "        assert self.num_heads == num_heads\n",
    "        assert self.single_head_dim == single_head_dim\n",
    "        # B x H x L x d   => \n",
    "        # B x L x H x d   =>\n",
    "        # B x L x D\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.query_matrix(Q))\n",
    "        K = self.split_heads(self.key_matrix(K))\n",
    "        V = self.split_heads(self.value_matrix(V))        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        return self.mixer(self.combine_heads(attn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, expansion):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(embed_dim, embed_dim * expansion)\n",
    "        self.fc2 = torch.nn.Linear(embed_dim * expansion, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # expand => non-linearity => shrink\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # (attention => droupout) + residual => norm\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, mask)))\n",
    "        # (MLP => dropout) + residual => norm\n",
    "        return self.norm2(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # self attention (decoder x decoder)\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, tgt_mask)))\n",
    "        # cross attention (decoder x encoder), note that queries are from decoder, keys and values - from encoder\n",
    "        x = self.norm2(x + self.dropout(self.cross_attn(x, encoder_output, encoder_output, src_mask)))\n",
    "        # MLP + dropout + residual + norm\n",
    "        return self.norm3(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        # we could split encoder and decoder embeddings\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.encoder_layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = torch.nn.ModuleList([DecoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.embedding(tgt)))\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):\n",
    "        mask = (src != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = src.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(src.device)\n",
    "        mask = mask & nopeak_mask\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self.generate_mask(src)\n",
    "        embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        for layer in self.layers:\n",
    "            embedded = layer(embedded, mask)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458199\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "all_shakespeare = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\").content.decode()\n",
    "print(len(all_shakespeare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<empty>', '<start>', '<end>', 'n', '|', 's', 'h', 'i', ' ', 'U', ']', '?', '_', 'J', '0', '-', '&', 'N', ';', '}', '5', '9', '!', 't', 'F', 'L', 'o', 'Q', ':', 'B', 'f', 'T', 'K', '\\n', '2', 'R', '#', 'g', 'P', ',', '<', 'G', 'M', '*', '.', 'D', 'j', '`', '/', '[', 'l', 'x', 'I', '1', 'H', 'C', 'q', '~', 'v', 'w', 'z', 'd', '(', '=', 'Y', '%', 'b', 'W', '@', '6', 'X', 'V', 'k', 'A', 'r', 'y', 'u', 'O', 'm', '\"', 'Z', '7', 'a', 'p', 'E', '3', 'e', '>', \"'\", '4', '8', ')', 'c', 'S']\n",
      "94\n",
      "{'<empty>': 0, '<start>': 1, '<end>': 2, 'n': 3, '|': 4, 's': 5, 'h': 6, 'i': 7, ' ': 8, 'U': 9, ']': 10, '?': 11, '_': 12, 'J': 13, '0': 14, '-': 15, '&': 16, 'N': 17, ';': 18, '}': 19, '5': 20, '9': 21, '!': 22, 't': 23, 'F': 24, 'L': 25, 'o': 26, 'Q': 27, ':': 28, 'B': 29, 'f': 30, 'T': 31, 'K': 32, '\\n': 33, '2': 34, 'R': 35, '#': 36, 'g': 37, 'P': 38, ',': 39, '<': 40, 'G': 41, 'M': 42, '*': 43, '.': 44, 'D': 45, 'j': 46, '`': 47, '/': 48, '[': 49, 'l': 50, 'x': 51, 'I': 52, '1': 53, 'H': 54, 'C': 55, 'q': 56, '~': 57, 'v': 58, 'w': 59, 'z': 60, 'd': 61, '(': 62, '=': 63, 'Y': 64, '%': 65, 'b': 66, 'W': 67, '@': 68, '6': 69, 'X': 70, 'V': 71, 'k': 72, 'A': 73, 'r': 74, 'y': 75, 'u': 76, 'O': 77, 'm': 78, '\"': 79, 'Z': 80, '7': 81, 'a': 82, 'p': 83, 'E': 84, '3': 85, 'e': 86, '>': 87, \"'\": 88, '4': 89, '8': 90, ')': 91, 'c': 92, 'S': 93}\n"
     ]
    }
   ],
   "source": [
    "dictionary = [\"<empty>\", \"<start>\", \"<end>\"] + list(set(all_shakespeare))\n",
    "print(dictionary)\n",
    "print(len(dictionary))\n",
    "\n",
    "sym2idx = {s: i for i, s in enumerate(dictionary)}\n",
    "print(sym2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85285\n",
      "To your notorious shame, I doubt it not.\n",
      "\n",
      "Enter DROMIO OF SYRAC\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "#data = all_shakespeare.split(\"\\n\\n\")\n",
    "#data = list(filter(lambda x: x and len(x) < max_seq_len, data))\n",
    "data = [all_shakespeare[i:i+max_seq_len-1] for i in range(0, len(all_shakespeare), max_seq_len)]\n",
    "random.shuffle(data)\n",
    "\n",
    "print(len(data))\n",
    "print(data[77])\n",
    "print(len(data[77]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " both together heav'd it up,\n",
      "    We'll both together lift our h\n",
      "\n",
      "salute him\n",
      "\n",
      "    A noble company! What are their pleasures?\n",
      "  CH\n"
     ]
    }
   ],
   "source": [
    "train = [data[i] for i in range(len(data)) if i % 10 != 0]\n",
    "test = [data[i] for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "print(train[-5])\n",
    "print(\"\")\n",
    "print(test[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True, False, False, False],\n",
      "          [ True,  True, False, False],\n",
      "          [ True,  True,  True, False],\n",
      "          [False, False, False, False]]]], device='cuda:0')\n",
      "6360158\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([[1, 2, 3, 0]]).to(device)\n",
    "model = Encoder(len(dictionary), 256, 8, 8, 4, max_seq_len, 0.1).to(device)\n",
    "mask = model.generate_mask(src)\n",
    "print(mask)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar:IT1rpGH/C/<3vIC=o[,/%HhIU::t)K;FL|\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate(model, len_limit):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = [\"<start>\"] + list(\"Caesar:\")\n",
    "        while len(result) < len_limit:\n",
    "            x = torch.tensor([[sym2idx[x] for x in result]]).to(device)\n",
    "            y = model(x)\n",
    "            y = y[0][-1].cpu().numpy()\n",
    "            y = np.exp(y)\n",
    "            y /= np.sum(y)\n",
    "            #print(\" \".join(map(lambda t: \"{:.4f}\".format(t), y)) + \"\\n\")\n",
    "            x = dictionary[np.random.choice(y.shape[0], p = y)]\n",
    "            if x in [\"<start>\", \"<end>\", \"<empty>\"]:\n",
    "                break\n",
    "            result.append(x)\n",
    "        return ''.join(result[1:])\n",
    "\n",
    "print(generate(model, max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:02<00:00, 1219.44it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3596.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.19827 2.64168\n",
      "Caesar: int\n",
      "O, ws s'Thil\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.71it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3594.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.03820 1.66827\n",
      "Caesar: engred like elrea,\n",
      "    And yAnger by with your \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.63it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3594.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 1.66384 1.50724\n",
      "Caesar:\n",
      "  Purch. Ay, sir, for him; len fair confits!\n",
      "  BETIP. I\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1218.33it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3597.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 1.54226 1.46378\n",
      "Caesar:\n",
      "     And now us.\n",
      "    Even troubate, am I'll from I hold\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.79it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3599.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 1.46231 1.39842\n",
      "Caesar: which livers is the unfinesly mysckon's life,\n",
      "    And f\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.79it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3598.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 1.41885 1.36049\n",
      "Caesar: I would not lodge, and myself;\n",
      "    To pread it the comf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.88it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3595.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 1.38385 1.34296\n",
      "Caesar: a sight of Lord Antonio.\n",
      "\n",
      "\n",
      "\n",
      "SCENE VII.\n",
      "Friaris, a Tent.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.86it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3597.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 1.35570 1.32310\n",
      "Caesar: with miles, and Third and Romeo, lieve,\n",
      "    Should not \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.79it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3596.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 1.33345 1.31476\n",
      "Caesar: our teacherous more.\n",
      "                                  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76756/76756 [01:03<00:00, 1216.87it/s]\n",
      "100%|██████████| 8529/8529 [00:02<00:00, 3597.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 1.32416 1.30640\n",
      "Caesar:\n",
      "         Fie, I will consider to thee at his way.\n",
      "  \n",
      "  \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def iterate_batches(data, batch_size, device):\n",
    "    x, y, max_len = [], [], 0\n",
    "    for k in tqdm.tqdm(range(len(data))):\n",
    "        item = data[k]\n",
    "        x.append([sym2idx[sym] for sym in [\"<start>\"] + list(item)])\n",
    "        y.append([sym2idx[sym] for sym in list(item) + [\"<end>\"]])\n",
    "        max_len = max(max_len, len(x[-1]))\n",
    "        if len(x) == batch_size or k + 1 == len(data):\n",
    "            for i in range(len(x)):\n",
    "                x[i] = x[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(x[i]))]\n",
    "                y[i] = y[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(y[i]))]\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "            yield x, y\n",
    "            x, y, max_len = [], [], 0\n",
    "        \n",
    "\n",
    "def train_epoch(data, model):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    total_loss, total_count = 0.0, 1e-38\n",
    "    random.shuffle(data)\n",
    "    for inputs, answers in iterate_batches(data, 256, device):\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs.shape)\n",
    "        #print(answers.shape)\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.shape)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        #print(outputs.shape)\n",
    "        #print(\"\")\n",
    "        loss = loss_function(outputs, answers)\n",
    "        total_loss += (loss.item() * inputs.shape[0])\n",
    "        total_count += inputs.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def test_epoch(data, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        total_loss, total_count = 0.0, 1e-38\n",
    "        for inputs, answers in iterate_batches(data, 256, device):\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.transpose(1, 2)\n",
    "            loss = loss_function(outputs, answers)\n",
    "            total_loss += (loss.item() * inputs.shape[0])\n",
    "            total_count += inputs.shape[0]\n",
    "        return total_loss / total_count\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for i in range(10):\n",
    "    train_loss = train_epoch(train, model)\n",
    "    test_loss = test_epoch(test, model)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Epoch {} loss: {:.5f} {:.5f}\".format(i, train_loss, test_loss))\n",
    "    print(generate(model, max_seq_len))\n",
    "    print(\"\")\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
