{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac213b3c-e25b-4137-ba6b-4063d59ed06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, dict_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dict_size = dict_size\n",
    "        self.embeddings = torch.nn.Embedding(dict_size, hidden_size)\n",
    "        self.wh = torch.nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.wy = torch.nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.uh = torch.nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.bh = torch.nn.Parameter(torch.randn(hidden_size))\n",
    "        self.by = torch.nn.Parameter(torch.randn(hidden_size))\n",
    "        self.projection = torch.nn.Linear(hidden_size, dict_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embeddings(torch.tensor([x]))\n",
    "        h = torch.sigmoid(self.wh(x) + self.uh(h) + self.bh)\n",
    "        y = self.projection(torch.sigmoid(self.wy(h) + self.by))\n",
    "        return y, h\n",
    "\n",
    "    def zero_state(self):\n",
    "        return torch.zeros(self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0756c7-8063-4b86-96d8-1349a4d0c208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458199\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "all_shakespeare = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\").content.decode()\n",
    "print(len(all_shakespeare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e430b7b1-3029-440f-b762-e4104d735c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', ',', 'K', 'I', '*', 'L', ')', 'H', 'm', '7', 'd', '.', 'o', 'a', ':', '6', '1', 'y', ']', 'f', 'u', 'e', '8', 'W', 'Z', '_', 'k', '4', 'b', 'J', 'U', 'O', 'q', 'i', 'p', 'S', '`', '\"', 'n', 'V', 'r', 'C', '[', 'j', 'X', 'w', 'B', '3', '=', 'E', 'v', '!', ' ', 'l', 'F', '/', ';', 'Y', 'g', '0', '<', '|', 'z', 'h', '%', 'D', '&', 'R', 't', 's', '#', 'Q', '(', '2', '}', \"'\", 'x', 'M', '>', 'P', 'T', 'N', '5', 'A', 'G', 'c', '-', '@', '~', '\\n', '9', '<start>', '<end>']\n",
      "93\n",
      "{'?': 0, ',': 1, 'K': 2, 'I': 3, '*': 4, 'L': 5, ')': 6, 'H': 7, 'm': 8, '7': 9, 'd': 10, '.': 11, 'o': 12, 'a': 13, ':': 14, '6': 15, '1': 16, 'y': 17, ']': 18, 'f': 19, 'u': 20, 'e': 21, '8': 22, 'W': 23, 'Z': 24, '_': 25, 'k': 26, '4': 27, 'b': 28, 'J': 29, 'U': 30, 'O': 31, 'q': 32, 'i': 33, 'p': 34, 'S': 35, '`': 36, '\"': 37, 'n': 38, 'V': 39, 'r': 40, 'C': 41, '[': 42, 'j': 43, 'X': 44, 'w': 45, 'B': 46, '3': 47, '=': 48, 'E': 49, 'v': 50, '!': 51, ' ': 52, 'l': 53, 'F': 54, '/': 55, ';': 56, 'Y': 57, 'g': 58, '0': 59, '<': 60, '|': 61, 'z': 62, 'h': 63, '%': 64, 'D': 65, '&': 66, 'R': 67, 't': 68, 's': 69, '#': 70, 'Q': 71, '(': 72, '2': 73, '}': 74, \"'\": 75, 'x': 76, 'M': 77, '>': 78, 'P': 79, 'T': 80, 'N': 81, '5': 82, 'A': 83, 'G': 84, 'c': 85, '-': 86, '@': 87, '~': 88, '\\n': 89, '9': 90, '<start>': 91, '<end>': 92}\n"
     ]
    }
   ],
   "source": [
    "dictionary = list(set(all_shakespeare))\n",
    "dictionary.append(\"<start>\")\n",
    "dictionary.append(\"<end>\")\n",
    "print(dictionary)\n",
    "print(len(dictionary))\n",
    "\n",
    "sym2idx = {s: i for i, s in enumerate(dictionary)}\n",
    "print(sym2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f614ff-5038-4d07-b516-7997535301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.9266e+00,  3.7460e-01, -8.4192e-01,  5.7829e-01,  1.5031e-01,\n",
      "        -7.6483e-01,  1.3104e+00, -7.5613e-01, -1.3940e+00,  9.4137e-01,\n",
      "         4.6848e-01,  4.9371e-01,  9.7709e-01, -8.1185e-01, -3.9525e-02,\n",
      "         1.2366e+00, -1.6081e-01,  9.1398e-02, -9.4032e-01, -1.7903e-02,\n",
      "         3.1462e-01,  5.3082e-01,  5.8745e-01,  8.0033e-01, -6.9968e-01,\n",
      "        -9.3662e-01,  7.6308e-02, -5.8648e-01, -2.3810e+00, -3.1006e-01,\n",
      "         9.5466e-02, -2.7594e+00, -1.3723e+00,  3.0150e-01,  8.1697e-01,\n",
      "        -5.8202e-01,  7.6177e-01, -1.3148e+00, -1.1513e-02,  6.1183e-01,\n",
      "         8.3423e-02, -8.2471e-01, -6.9657e-01,  8.7332e-01,  1.2039e+00,\n",
      "         3.5023e-01,  1.7394e+00,  2.2808e-03,  2.0652e+00,  4.5765e-01,\n",
      "        -1.6390e-01,  4.2148e-01,  7.1645e-01,  5.6960e-01, -1.8987e+00,\n",
      "        -2.8255e-01, -1.6632e-01, -2.3588e+00,  5.7328e-01,  3.2845e-01,\n",
      "        -1.0897e-01,  1.3576e+00, -3.9493e-01, -1.3344e+00, -1.1869e+00,\n",
      "         6.4032e-01,  9.7548e-01, -4.6635e-01,  4.1898e-01, -6.9559e-01,\n",
      "        -1.8622e-01,  1.1701e-01,  1.1831e+00,  1.0190e+00, -1.4011e+00,\n",
      "         8.0165e-01, -4.3876e-01, -1.9537e-01,  6.9401e-01,  8.5215e-01,\n",
      "         6.5322e-01,  2.0949e-01, -2.6168e+00,  3.5167e-02,  1.2245e+00,\n",
      "         2.1320e-01, -1.0031e+00,  1.2188e+00,  1.3810e+00, -8.2079e-02,\n",
      "        -1.0930e-01, -1.1251e+00, -4.3843e-01, -7.0121e-02,  5.8126e-01,\n",
      "         6.4902e-01,  6.6062e-01,  2.0906e+00, -1.4957e-01,  1.6640e+00,\n",
      "         2.4535e-01, -1.3226e-01, -5.3363e-01, -1.0636e+00, -4.5422e-01,\n",
      "        -2.3752e-01, -6.1511e-01,  4.1152e-01, -1.4932e+00, -8.3147e-01,\n",
      "        -9.0998e-01, -1.1969e+00,  5.9685e-01,  1.3549e+00, -6.7149e-01,\n",
      "        -7.9159e-01, -2.1708e+00,  1.0829e+00,  7.5783e-01, -3.9185e-01,\n",
      "         1.2874e+00,  1.4637e+00, -1.2147e+00,  4.1811e-01, -1.9226e-01,\n",
      "        -6.4735e-01, -1.0420e+00,  2.7271e-01], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.7869,  0.4224,  0.9971, -0.1735, -0.0404, -1.0682,  1.7806, -0.1460,\n",
      "         0.4430, -1.2196, -1.2298, -0.0181,  1.3048, -0.8238, -1.1985, -0.7489,\n",
      "         1.4046,  0.0377, -0.4629, -1.7856, -0.1664, -1.7444,  0.4161,  0.1183,\n",
      "        -1.8485,  0.4516, -0.0298,  0.2166,  0.3914,  0.7070, -0.3329, -0.0222,\n",
      "        -0.8039, -0.3435,  1.0844,  0.8798,  1.1512, -0.0932, -0.1536, -0.1594,\n",
      "        -0.1366, -1.8766, -1.1490,  0.2349, -0.6140, -1.3508,  0.6474,  0.4843,\n",
      "         1.2724,  0.0363, -0.2080, -0.7254,  0.8215, -0.3184, -0.2232, -1.2069,\n",
      "         1.6342,  0.9187,  0.6846, -0.0154,  0.5133, -0.1977, -0.4486, -0.0855,\n",
      "         0.2794,  0.3789, -1.4023, -0.0978, -1.2518, -1.4680, -0.0825,  0.9628,\n",
      "         1.2938, -0.3871, -2.0520,  0.2625, -0.8153,  0.2503, -0.4884, -0.0057,\n",
      "         0.0966,  1.8324,  0.6313,  1.4131, -1.0600,  1.0351,  0.2867, -2.3086,\n",
      "        -0.5165,  0.6154,  1.3795,  0.5740, -1.4302, -0.0168,  0.4311, -0.5434,\n",
      "         0.1493,  2.0983,  0.9734, -0.1682,  0.7876,  2.0675,  0.1099,  0.8198,\n",
      "         1.7635, -0.0836,  0.0826,  0.2450,  0.1500, -1.6135, -1.1204,  0.3463,\n",
      "        -0.5219, -1.4436,  0.6330, -0.0050, -0.4635,  1.5555,  0.5893, -0.4719,\n",
      "        -0.6009, -1.8241,  0.5657,  1.0167,  0.7075, -1.2571,  0.5283,  0.0708],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4224, -1.3320, -1.4223,  ..., -0.1320, -0.6107, -0.2613],\n",
      "        [-0.8748, -0.0632, -0.5520,  ..., -1.1774,  0.6150,  0.1419],\n",
      "        [ 0.5310, -0.6764,  0.1345,  ...,  0.8987,  1.2578,  1.2156],\n",
      "        ...,\n",
      "        [-2.1355,  1.6696,  0.0889,  ...,  0.0154, -0.7174, -0.6265],\n",
      "        [ 1.3068,  0.9706,  0.2151,  ...,  0.1440,  1.2084, -1.0587],\n",
      "        [ 0.4360, -0.0602,  0.5383,  ...,  0.8322, -1.1364,  0.6022]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0197, -0.0680, -0.0755,  ...,  0.0700,  0.0626,  0.0093],\n",
      "        [-0.0465,  0.0228,  0.0864,  ..., -0.0232, -0.0090, -0.0835],\n",
      "        [-0.0347,  0.0370,  0.0419,  ..., -0.0723, -0.0260,  0.0400],\n",
      "        ...,\n",
      "        [ 0.0258,  0.0474, -0.0481,  ..., -0.0016, -0.0260, -0.0681],\n",
      "        [ 0.0116, -0.0058, -0.0040,  ..., -0.0040,  0.0143, -0.0164],\n",
      "        [ 0.0414,  0.0680,  0.0729,  ..., -0.0388, -0.0574,  0.0164]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0654, -0.0713,  0.0430,  ...,  0.0524,  0.0739,  0.0104],\n",
      "        [-0.0023, -0.0255,  0.0526,  ..., -0.0227, -0.0820,  0.0863],\n",
      "        [-0.0726,  0.0167,  0.0324,  ...,  0.0579, -0.0606, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0810,  0.0576, -0.0330,  ..., -0.0735, -0.0763,  0.0867],\n",
      "        [ 0.0186,  0.0587, -0.0872,  ..., -0.0832,  0.0532, -0.0607],\n",
      "        [ 0.0036, -0.0583, -0.0097,  ...,  0.0807,  0.0658, -0.0424]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0826,  0.0300, -0.0568,  ...,  0.0301, -0.0751,  0.0712],\n",
      "        [ 0.0491,  0.0147,  0.0880,  ...,  0.0400,  0.0172,  0.0639],\n",
      "        [-0.0357, -0.0877, -0.0867,  ..., -0.0618,  0.0274,  0.0517],\n",
      "        ...,\n",
      "        [ 0.0075,  0.0827, -0.0548,  ...,  0.0275,  0.0310,  0.0013],\n",
      "        [ 0.0686,  0.0502, -0.0185,  ...,  0.0200, -0.0383,  0.0837],\n",
      "        [ 0.0122, -0.0028,  0.0839,  ..., -0.0160, -0.0571,  0.0399]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0002,  0.0102,  0.0677,  ...,  0.0848, -0.0543, -0.0490],\n",
      "        [ 0.0618,  0.0159,  0.0768,  ...,  0.0040,  0.0024, -0.0338],\n",
      "        [-0.0799, -0.0539, -0.0336,  ...,  0.0386, -0.0621, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0204, -0.0108, -0.0705,  ..., -0.0564, -0.0073, -0.0632],\n",
      "        [ 0.0363, -0.0046,  0.0292,  ..., -0.0790, -0.0874, -0.0303],\n",
      "        [ 0.0635,  0.0087,  0.0735,  ...,  0.0407,  0.0648,  0.0297]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0666,  0.0880, -0.0380,  0.0855,  0.0718,  0.0223,  0.0599, -0.0441,\n",
      "        -0.0638, -0.0137,  0.0182, -0.0207, -0.0059,  0.0863, -0.0794,  0.0192,\n",
      "         0.0702, -0.0693,  0.0760, -0.0317,  0.0673,  0.0608,  0.0356, -0.0752,\n",
      "        -0.0333, -0.0311,  0.0852,  0.0501, -0.0101, -0.0521,  0.0563,  0.0878,\n",
      "        -0.0742, -0.0525, -0.0819, -0.0648, -0.0606, -0.0794, -0.0639, -0.0634,\n",
      "         0.0078,  0.0201,  0.0251, -0.0852, -0.0762,  0.0753,  0.0302,  0.0029,\n",
      "        -0.0241,  0.0368, -0.0719,  0.0669,  0.0027,  0.0047,  0.0097, -0.0820,\n",
      "         0.0252, -0.0528, -0.0623,  0.0656,  0.0227,  0.0679, -0.0053,  0.0463,\n",
      "         0.0625,  0.0223, -0.0394,  0.0786,  0.0814,  0.0852,  0.0434,  0.0497,\n",
      "         0.0611, -0.0683, -0.0536, -0.0310, -0.0342,  0.0187,  0.0063,  0.0624,\n",
      "        -0.0101, -0.0518,  0.0334,  0.0352,  0.0472,  0.0797,  0.0096, -0.0418,\n",
      "        -0.0235,  0.0734, -0.0722, -0.0265,  0.0518], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(128, len(dictionary))\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc71e55-dab9-4219-8e9c-88de3cd041a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6483\n",
      "  SICINIUS. Well, here he comes.\n",
      "  MENENIUS. Calmly, I do beseech you.\n",
      "  CORIOLANUS. Ay, as an ostler, that for th' poorest piece\n",
      "    Will bear the knave by th' volume. Th' honour'd gods\n",
      "    Keep Rome in safety, and the chairs of justice\n",
      "    Supplied with worthy men! plant love among's!\n",
      "    Throng our large temples with the shows of peace,\n",
      "    And not our streets with war!\n",
      "  FIRST SENATOR. Amen, amen!\n",
      "  MENENIUS. A noble wish.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "data = all_shakespeare.split(\"\\n\\n\")\n",
    "data = list(filter(lambda x: x, data))\n",
    "random.shuffle(data)\n",
    "\n",
    "print(len(data))\n",
    "print(data[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c18d7ee-89db-49bf-8dbc-2ce5308cd2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRANIO. Gentlemen, God save you! If I may be bold,\n",
      "    Tell me, I beseech you, which is the readiest way\n",
      "    To the house of Signior Baptista Minola?\n",
      "  BIONDELLO. He that has the two fair daughters; is't he you mean?\n",
      "  TRANIO. Even he, Biondello.\n",
      "  GREMIO. Hark you, sir, you mean not her to-\n",
      "  TRANIO. Perhaps him and her, sir; what have you to do?\n",
      "  PETRUCHIO. Not her that chides, sir, at any hand, I pray.\n",
      "  TRANIO. I love no chiders, sir. Biondello, let's away.\n",
      "  LUCENTIO.  [Aside]  Well begun, Tranio.\n",
      "  HORTENSIO. Sir, a word ere you go.\n",
      "    Are you a suitor to the maid you talk of, yea or no?\n",
      "  TRANIO. And if I be, sir, is it any offence?\n",
      "  GREMIO. No; if without more words you will get you hence.  \n",
      "  TRANIO. Why, sir, I pray, are not the streets as free\n",
      "    For me as for you?\n",
      "  GREMIO. But so is not she.\n",
      "\n",
      "ALLS WELL THAT ENDS WELL\n"
     ]
    }
   ],
   "source": [
    "train = [data[i] for i in range(len(data)) if i % 10 != 0]\n",
    "test = [data[i] for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "print(train[-1])\n",
    "print(\"\")\n",
    "print(test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef210c4-60ef-479d-8e0d-d83b1fbb2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [39:35<00:00,  2.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:40<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 2.09608 1.79229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [40:30<00:00,  2.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:40<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.71768 1.65485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [40:29<00:00,  2.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:40<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.60903 1.58000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [43:31<00:00,  2.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:40<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.54108 1.52630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [40:35<00:00,  2.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:39<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.49041 1.48451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [45:34<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [02:00<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.45054 1.45102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [42:55<00:00,  2.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [02:05<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.41798 1.42423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [48:33<00:00,  2.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [02:00<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.39086 1.40252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [48:27<00:00,  2.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:59<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.36880 1.38364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5834/5834 [41:40<00:00,  2.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 649/649 [01:40<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.34822 1.36728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def train_epoch(data, model):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    total_loss, total_count = 0.0, 1e-38\n",
    "    for item in tqdm.tqdm(data):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = []\n",
    "        answers = torch.tensor([sym2idx[sym] for sym in list(item) + [\"<end>\"]])\n",
    "        state = model.zero_state()\n",
    "        for i, x in enumerate([\"<start>\"] + list(item)):\n",
    "            y, state = model(sym2idx[x], state)\n",
    "            outputs.append(y)\n",
    "        outputs = torch.cat(outputs)\n",
    "        #print(outputs.shape)\n",
    "        #print(answers.shape)\n",
    "        #print(outputs)\n",
    "        loss = loss_function(outputs, answers)\n",
    "        total_loss += loss.item()\n",
    "        total_count += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def test_epoch(data, model):\n",
    "    model.eval()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    total_loss, total_count = 0.0, 1e-38\n",
    "    for item in tqdm.tqdm(data):\n",
    "        outputs = []\n",
    "        answers = torch.tensor([sym2idx[sym] for sym in list(item) + [\"<end>\"]])\n",
    "        state = model.zero_state()\n",
    "        for i, x in enumerate([\"<start>\"] + list(item)):\n",
    "            y, state = model(sym2idx[x], state)\n",
    "            outputs.append(y)\n",
    "        outputs = torch.cat(outputs)\n",
    "        loss = loss_function(outputs, answers)\n",
    "        total_loss += loss.item()\n",
    "        total_count += 1\n",
    "    return total_loss / total_count\n",
    "\n",
    "for _ in range(10):\n",
    "    train_loss = train_epoch(train, model)\n",
    "    test_loss = test_epoch(test, model)\n",
    "    print(\"Epoch loss: {:.5f} {:.5f}\".format(train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866b951-0365-451d-b507-105b1f0df338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
