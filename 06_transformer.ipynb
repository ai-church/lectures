{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "max_seq_len = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        pe = torch.zeros(max_seq_len, self.embed_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (2 * i / self.embed_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * (i + 1) / self.embed_dim)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)       # pre-calculate and freeze\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x * math.sqrt(self.embed_dim) + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        # return x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.single_head_dim = self.embed_dim // self.num_heads   # 512 / 8 = 64, every head takes its part of the input\n",
    "        self.query_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)  # a big matrix for the whole input\n",
    "        self.key_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)    # we will split the heads later on\n",
    "        self.value_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.mixer = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Q, K, V shapes are (batch x length x single_head_dim) == (32 x 10 x 64)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.single_head_dim)\n",
    "        # scores shape is (batch x length x length) == (32 x 10 x 10)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == False, -1e9)    # put large negative numbers to positions where mask == False\n",
    "        probs = torch.softmax(scores, dim=-1)                   # transform scores to probabilities (B x L x L)\n",
    "                                                                # for each sample in the batch tell how ith token is important to jth token\n",
    "        return torch.matmul(probs, V)                           # re-weigh values according to the probabilities\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()            # B x L x D\n",
    "        assert self.embed_dim == embed_dim\n",
    "        return x.view(                                          # B x L x H x d\n",
    "            batch_size,\n",
    "            seq_length,\n",
    "            self.num_heads,\n",
    "            self.single_head_dim,\n",
    "        ).transpose(1, 2)                                       # B x H x L x d\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, single_head_dim = x.size()\n",
    "        assert self.num_heads == num_heads\n",
    "        assert self.single_head_dim == single_head_dim\n",
    "        # B x H x L x d   => \n",
    "        # B x L x H x d   =>\n",
    "        # B x L x D\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.query_matrix(Q))\n",
    "        K = self.split_heads(self.key_matrix(K))\n",
    "        V = self.split_heads(self.value_matrix(V))        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        return self.mixer(self.combine_heads(attn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, expansion):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(embed_dim, embed_dim * expansion)\n",
    "        self.fc2 = torch.nn.Linear(embed_dim * expansion, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # expand => non-linearity => shrink\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # (attention => droupout) + residual => norm\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, mask)))\n",
    "        # (MLP => dropout) + residual => norm\n",
    "        return self.norm2(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # self attention (decoder x decoder)\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, tgt_mask)))\n",
    "        # cross attention (decoder x encoder), note that queries are from decoder, keys and values - from encoder\n",
    "        x = self.norm2(x + self.dropout(self.cross_attn(x, encoder_output, encoder_output, src_mask)))\n",
    "        # MLP + dropout + residual + norm\n",
    "        return self.norm3(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        # we could split encoder and decoder embeddings\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.encoder_layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = torch.nn.ModuleList([DecoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.embedding(tgt)))\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):\n",
    "        mask = (src != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = src.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(src.device)\n",
    "        mask = mask & nopeak_mask\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self.generate_mask(src)\n",
    "        embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        for layer in self.layers:\n",
    "            embedded = layer(embedded, mask)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458199\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "all_shakespeare = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\").content.decode()\n",
    "print(len(all_shakespeare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<empty>', '<start>', '<end>', '*', '_', 'e', \"'\", ':', '8', '`', 'X', '|', '#', '7', ')', 'S', ';', '&', 'B', ',', ']', '!', '?', '5', 'M', '[', '(', 'D', 'G', 'A', '/', 'd', 'E', 'r', 's', 't', 'l', 'W', 'T', 'H', 'Y', '=', '4', 'P', 'm', '%', 'n', 'R', '>', 'N', 'j', '<', 'h', 'b', '2', 'L', 'w', '1', 'a', 'q', 'z', 'Q', '~', '0', '9', '6', 'I', 'C', 'o', 'O', 'F', 'f', 'g', 'p', 'K', '-', '\"', ' ', '}', 'y', 'u', 'k', '.', '@', 'c', '\\n', 'Z', 'v', 'i', 'J', 'U', 'x', 'V', '3']\n",
      "94\n",
      "{'<empty>': 0, '<start>': 1, '<end>': 2, '*': 3, '_': 4, 'e': 5, \"'\": 6, ':': 7, '8': 8, '`': 9, 'X': 10, '|': 11, '#': 12, '7': 13, ')': 14, 'S': 15, ';': 16, '&': 17, 'B': 18, ',': 19, ']': 20, '!': 21, '?': 22, '5': 23, 'M': 24, '[': 25, '(': 26, 'D': 27, 'G': 28, 'A': 29, '/': 30, 'd': 31, 'E': 32, 'r': 33, 's': 34, 't': 35, 'l': 36, 'W': 37, 'T': 38, 'H': 39, 'Y': 40, '=': 41, '4': 42, 'P': 43, 'm': 44, '%': 45, 'n': 46, 'R': 47, '>': 48, 'N': 49, 'j': 50, '<': 51, 'h': 52, 'b': 53, '2': 54, 'L': 55, 'w': 56, '1': 57, 'a': 58, 'q': 59, 'z': 60, 'Q': 61, '~': 62, '0': 63, '9': 64, '6': 65, 'I': 66, 'C': 67, 'o': 68, 'O': 69, 'F': 70, 'f': 71, 'g': 72, 'p': 73, 'K': 74, '-': 75, '\"': 76, ' ': 77, '}': 78, 'y': 79, 'u': 80, 'k': 81, '.': 82, '@': 83, 'c': 84, '\\n': 85, 'Z': 86, 'v': 87, 'i': 88, 'J': 89, 'U': 90, 'x': 91, 'V': 92, '3': 93}\n"
     ]
    }
   ],
   "source": [
    "dictionary = [\"<empty>\", \"<start>\", \"<end>\"] + list(set(all_shakespeare))\n",
    "print(dictionary)\n",
    "print(len(dictionary))\n",
    "\n",
    "sym2idx = {s: i for i, s in enumerate(dictionary)}\n",
    "print(sym2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42643\n",
      "If the tagrag people did not clap him and hiss him\n",
      "    according as he pleased and displeased them, as they use to do\n",
      "    the p\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "#data = all_shakespeare.split(\"\\n\\n\")\n",
    "#data = list(filter(lambda x: x and len(x) < max_seq_len, data))\n",
    "data = [all_shakespeare[i:i+max_seq_len-1] for i in range(0, len(all_shakespeare), max_seq_len)]\n",
    "random.shuffle(data)\n",
    "\n",
    "print(len(data))\n",
    "print(data[77])\n",
    "print(len(data[77]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " both together heav'd it up,\n",
      "    We'll both together lift our heads to heaven,\n",
      "    And never more abase our sight so low\n",
      "    As\n",
      "\n",
      "thee.\n",
      "  PRINCESS OF FRANCE. Honey, and milk, and sugar; there is three.\n",
      "  BEROWNE. Nay, then, two treys, an if you grow so nice\n"
     ]
    }
   ],
   "source": [
    "train = [data[i] for i in range(len(data)) if i % 10 != 0]\n",
    "test = [data[i] for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "print(train[-5])\n",
    "print(\"\")\n",
    "print(test[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True, False, False, False],\n",
      "          [ True,  True, False, False],\n",
      "          [ True,  True,  True, False],\n",
      "          [False, False, False, False]]]], device='cuda:0')\n",
      "3190366\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([[1, 2, 3, 0]]).to(device)\n",
    "model = Encoder(len(dictionary), 256, 8, 16, 4, max_seq_len, 0.1).to(device)\n",
    "mask = model.generate_mask(src)\n",
    "print(mask)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar:}iZ3|%ZqcyDlNW\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate(model, len_limit):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = [\"<start>\"] + list(\"Caesar:\")\n",
    "        while len(result) < len_limit:\n",
    "            x = torch.tensor([[sym2idx[x] for x in result]]).to(device)\n",
    "            y = model(x)\n",
    "            y = y[0][-1].cpu().numpy()\n",
    "            y = np.exp(y)\n",
    "            y /= np.sum(y)\n",
    "            #print(\" \".join(map(lambda t: \"{:.4f}\".format(t), y)) + \"\\n\")\n",
    "            x = dictionary[np.random.choice(y.shape[0], p = y)]\n",
    "            if x in [\"<start>\", \"<end>\", \"<empty>\"]:\n",
    "                break\n",
    "            result.append(x)\n",
    "        return ''.join(result[1:])\n",
    "\n",
    "print(generate(model, max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 441.09it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.25431 3.21167\n",
      "Caesar:wln f e i.r \n",
      "  r ia \n",
      "s,om cgeefaa nfshivou       t  iNfw t faRcenSem ,hj,  H tsNett.ly      elr Ih\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.37it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.76041 2.44390\n",
      "Caesar:\n",
      "\n",
      " 1? MUANULLIPLETER Were INYESUS]9\n",
      "\n",
      "> RAOOV eur, hete IESILASOONOVENEke, JY omedvad Cotengheso d alof s d GEDECe me thi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.41it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1239.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 2.32230 2.22843\n",
      "Caesar: weats\n",
      "    I Hag habe, or noulie bate thaur tom\n",
      "  aitaion\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.41it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1239.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 2.11960 1.92640\n",
      "Caesar:\n",
      "  FRENSUTALE. Anllatce of I wor thening of hid ugh prigh.\n",
      "  KIND REDAMBARS BASTIUS, that he Colice,\n",
      "  ANTINCHAND. Dus-S\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.41it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 1.99695 1.82108\n",
      "Caesar: the have upreary come we he'll aront, and here withit that\n",
      "    all th's comtn are is minan; And; I, freave.\n",
      "  IF\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.44it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 1.90621 1.73433\n",
      "Caesar:\n",
      "    End now theyu, fir or tirscuren an swen'd\n",
      "    stire quen me thee Rome prosesur.\n",
      "\n",
      "   SENGSSARIUS. I dill hem gent an\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.49it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 1.77092 1.63603\n",
      "Caesar:\n",
      "    To have to  well now as thins barge me.\n",
      "   Yea. I say, my come your see\n",
      "     Lest my lords is lets is will pray bou\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.46it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 1.74087 1.59133\n",
      "Caesar: Evire let Julohn.\n",
      "  LUCEUS. What I make no stouble I should take nexite?\n",
      "  COSTRIUS. My shave grotcer meet, lost is the\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.50it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 1.72646 1.56052\n",
      "Caesar:\n",
      "                                                                            [Exit CELENABRIA\n",
      "  FRALDAFF. Let my say art\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:27<00:00, 440.45it/s]\n",
      "100%|██████████| 4265/4265 [00:03<00:00, 1240.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 1.64597 1.49715\n",
      "Caesar:\n",
      "    Feor anms your kingom, the conjoyst my knowder of my boke\n",
      "    our my keeps of all plaidy by more, for Yord!\n",
      "  KING \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def iterate_batches(data, batch_size, device):\n",
    "    x, y, max_len = [], [], 0\n",
    "    for k in tqdm.tqdm(range(len(data))):\n",
    "        item = data[k]\n",
    "        x.append([sym2idx[sym] for sym in [\"<start>\"] + list(item)])\n",
    "        y.append([sym2idx[sym] for sym in list(item) + [\"<end>\"]])\n",
    "        max_len = max(max_len, len(x[-1]))\n",
    "        if len(x) == batch_size or k + 1 == len(data):\n",
    "            for i in range(len(x)):\n",
    "                x[i] = x[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(x[i]))]\n",
    "                y[i] = y[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(y[i]))]\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "            yield x, y\n",
    "            x, y, max_len = [], [], 0\n",
    "        \n",
    "\n",
    "def train_epoch(data, model):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    total_loss, total_count = 0.0, 1e-38\n",
    "    random.shuffle(data)\n",
    "    for inputs, answers in iterate_batches(data, 256, device):\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs.shape)\n",
    "        #print(answers.shape)\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.shape)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        #print(outputs.shape)\n",
    "        #print(\"\")\n",
    "        loss = loss_function(outputs, answers)\n",
    "        total_loss += (loss.item() * inputs.shape[0])\n",
    "        total_count += inputs.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def test_epoch(data, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        total_loss, total_count = 0.0, 1e-38\n",
    "        for inputs, answers in iterate_batches(data, 256, device):\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.transpose(1, 2)\n",
    "            loss = loss_function(outputs, answers)\n",
    "            total_loss += (loss.item() * inputs.shape[0])\n",
    "            total_count += inputs.shape[0]\n",
    "        return total_loss / total_count\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for i in range(10):\n",
    "    train_loss = train_epoch(train, model)\n",
    "    test_loss = test_epoch(test, model)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Epoch {} loss: {:.5f} {:.5f}\".format(i, train_loss, test_loss))\n",
    "    print(generate(model, max_seq_len))\n",
    "    print(\"\")\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
