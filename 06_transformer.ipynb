{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "max_seq_len, embedding_size, head_count, layer_count, batch_size, epoch_count = 128, 256, 8, 8, 256, 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        pe = torch.zeros(max_seq_len, self.embed_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (2 * i / self.embed_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * (i + 1) / self.embed_dim)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)       # pre-calculate and freeze\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x * math.sqrt(self.embed_dim) + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        # return x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.single_head_dim = self.embed_dim // self.num_heads   # 512 / 8 = 64, every head takes its part of the input\n",
    "        self.query_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)  # a big matrix for the whole input\n",
    "        self.key_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)    # we will split the heads later on\n",
    "        self.value_matrix = torch.nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.mixer = torch.nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Q, K, V shapes are (batch x length x single_head_dim) == (32 x 10 x 64)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.single_head_dim)\n",
    "        # scores shape is (batch x length x length) == (32 x 10 x 10)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == False, -1e9)    # put large negative numbers to positions where mask == False\n",
    "        probs = torch.softmax(scores, dim=-1)                   # transform scores to probabilities (B x L x L)\n",
    "                                                                # for each sample in the batch tell how ith token is important to jth token\n",
    "        return torch.matmul(probs, V)                           # re-weigh values according to the probabilities\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()            # B x L x D\n",
    "        assert self.embed_dim == embed_dim\n",
    "        return x.view(                                          # B x L x H x d\n",
    "            batch_size,\n",
    "            seq_length,\n",
    "            self.num_heads,\n",
    "            self.single_head_dim,\n",
    "        ).transpose(1, 2)                                       # B x H x L x d\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, single_head_dim = x.size()\n",
    "        assert self.num_heads == num_heads\n",
    "        assert self.single_head_dim == single_head_dim\n",
    "        # B x H x L x d   => \n",
    "        # B x L x H x d   =>\n",
    "        # B x L x D\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.query_matrix(Q))\n",
    "        K = self.split_heads(self.key_matrix(K))\n",
    "        V = self.split_heads(self.value_matrix(V))        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        return self.mixer(self.combine_heads(attn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, expansion):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(embed_dim, embed_dim * expansion)\n",
    "        self.fc2 = torch.nn.Linear(embed_dim * expansion, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # expand => non-linearity => shrink\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # (attention => droupout) + residual => norm\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, mask)))\n",
    "        # (MLP => dropout) + residual => norm\n",
    "        return self.norm2(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, expansion, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, expansion)\n",
    "        self.norm1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # self attention (decoder x decoder)\n",
    "        x = self.norm1(x + self.dropout(self.self_attn(x, x, x, tgt_mask)))\n",
    "        # cross attention (decoder x encoder), note that queries are from decoder, keys and values - from encoder\n",
    "        x = self.norm2(x + self.dropout(self.cross_attn(x, encoder_output, encoder_output, src_mask)))\n",
    "        # MLP + dropout + residual + norm\n",
    "        return self.norm3(x + self.dropout(self.feed_forward(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        # we could split encoder and decoder embeddings\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.encoder_layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = torch.nn.ModuleList([DecoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.embedding(tgt)))\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, expansion, max_seq_length, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_length)\n",
    "        self.layers = torch.nn.ModuleList([EncoderLayer(embed_dim, num_heads, expansion, dropout) for _ in range(num_layers)])\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):\n",
    "        mask = (src != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = src.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(src.device)\n",
    "        mask = mask & nopeak_mask\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self.generate_mask(src)\n",
    "        embedded = self.dropout(self.positional_encoding(self.embedding(src)))\n",
    "        for layer in self.layers:\n",
    "            embedded = layer(embedded, mask)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458199\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "all_shakespeare = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\").content.decode()\n",
    "print(len(all_shakespeare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<empty>', '<start>', '<end>', '7', '[', 'p', '3', '1', '}', 'u', ']', 'v', '8', 'q', 's', '(', 'L', '%', '_', '#', 'I', ';', '4', '/', 'M', '-', '=', 'O', 't', 'z', '2', 'h', '>', ',', 'J', 'P', 'N', 'x', '&', '@', 'A', 'f', 'K', 'T', '0', '*', 'd', 'a', 'j', 'S', 'c', 'l', 'B', '\"', '.', ':', 'H', 'o', 'G', 'C', '?', 'e', 'E', 'r', 'X', 'w', '~', 'm', '9', '|', 'n', 'g', 'b', '`', 'U', 'V', '6', '5', 'Q', ' ', 'R', 'k', 'Z', 'i', '!', 'Y', 'W', '\\n', \"'\", ')', 'y', '<', 'F', 'D']\n",
      "94\n",
      "{'<empty>': 0, '<start>': 1, '<end>': 2, '7': 3, '[': 4, 'p': 5, '3': 6, '1': 7, '}': 8, 'u': 9, ']': 10, 'v': 11, '8': 12, 'q': 13, 's': 14, '(': 15, 'L': 16, '%': 17, '_': 18, '#': 19, 'I': 20, ';': 21, '4': 22, '/': 23, 'M': 24, '-': 25, '=': 26, 'O': 27, 't': 28, 'z': 29, '2': 30, 'h': 31, '>': 32, ',': 33, 'J': 34, 'P': 35, 'N': 36, 'x': 37, '&': 38, '@': 39, 'A': 40, 'f': 41, 'K': 42, 'T': 43, '0': 44, '*': 45, 'd': 46, 'a': 47, 'j': 48, 'S': 49, 'c': 50, 'l': 51, 'B': 52, '\"': 53, '.': 54, ':': 55, 'H': 56, 'o': 57, 'G': 58, 'C': 59, '?': 60, 'e': 61, 'E': 62, 'r': 63, 'X': 64, 'w': 65, '~': 66, 'm': 67, '9': 68, '|': 69, 'n': 70, 'g': 71, 'b': 72, '`': 73, 'U': 74, 'V': 75, '6': 76, '5': 77, 'Q': 78, ' ': 79, 'R': 80, 'k': 81, 'Z': 82, 'i': 83, '!': 84, 'Y': 85, 'W': 86, '\\n': 87, \"'\": 88, ')': 89, 'y': 90, '<': 91, 'F': 92, 'D': 93}\n"
     ]
    }
   ],
   "source": [
    "dictionary = [\"<empty>\", \"<start>\", \"<end>\"] + list(set(all_shakespeare))\n",
    "print(dictionary)\n",
    "print(len(dictionary))\n",
    "\n",
    "sym2idx = {s: i for i, s in enumerate(dictionary)}\n",
    "print(sym2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42643\n",
      "If the tagrag people did not clap him and hiss him\n",
      "    according as he pleased and displeased them, as they use to do\n",
      "    the p\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "#data = all_shakespeare.split(\"\\n\\n\")\n",
    "#data = list(filter(lambda x: x and len(x) < max_seq_len, data))\n",
    "data = [all_shakespeare[i:i+max_seq_len-1] for i in range(0, len(all_shakespeare), max_seq_len)]\n",
    "random.shuffle(data)\n",
    "\n",
    "print(len(data))\n",
    "print(data[77])\n",
    "print(len(data[77]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " both together heav'd it up,\n",
      "    We'll both together lift our heads to heaven,\n",
      "    And never more abase our sight so low\n",
      "    As\n",
      "\n",
      "thee.\n",
      "  PRINCESS OF FRANCE. Honey, and milk, and sugar; there is three.\n",
      "  BEROWNE. Nay, then, two treys, an if you grow so nice\n"
     ]
    }
   ],
   "source": [
    "train = [data[i] for i in range(len(data)) if i % 10 != 0]\n",
    "test = [data[i] for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "print(train[-5])\n",
    "print(\"\")\n",
    "print(test[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True, False, False, False],\n",
      "          [ True,  True, False, False],\n",
      "          [ True,  True,  True, False],\n",
      "          [False, False, False, False]]]], device='cuda:0')\n",
      "6360158\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([[1, 2, 3, 0]]).to(device)\n",
    "model = Encoder(len(dictionary), embedding_size, head_count, layer_count, 4, max_seq_len, 0.1).to(device)\n",
    "mask = model.generate_mask(src)\n",
    "print(mask)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar:'am1wvQu`Tg[w[(F}@S7}z[Dk\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate(model, len_limit):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = [\"<start>\"] + list(\"Caesar:\")\n",
    "        while len(result) < len_limit:\n",
    "            x = torch.tensor([[sym2idx[x] for x in result]]).to(device)\n",
    "            y = model(x)\n",
    "            y = y[0][-1].cpu().numpy()\n",
    "            y = np.exp(y)\n",
    "            y /= np.sum(y)\n",
    "            #print(\" \".join(map(lambda t: \"{:.4f}\".format(t), y)) + \"\\n\")\n",
    "            x = dictionary[np.random.choice(y.shape[0], p = y)]\n",
    "            if x in [\"<start>\", \"<end>\", \"<empty>\"]:\n",
    "                break\n",
    "            result.append(x)\n",
    "        return ''.join(result[1:])\n",
    "\n",
    "print(generate(model, max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38378/38378 [01:09<00:00, 550.61it/s]\n",
      "100%|██████████| 4265/4265 [00:02<00:00, 1564.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.25003 3.21192\n",
      "Caesar:i asnb Tuew uu tDdetaoPsAcmtmt.rmI,lndyeyR hh \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 19456/38378 [00:35<00:34, 549.39it/s]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def iterate_batches(data, batch_size, device):\n",
    "    x, y, max_len = [], [], 0\n",
    "    for k in tqdm.tqdm(range(len(data))):\n",
    "        item = data[k]\n",
    "        x.append([sym2idx[sym] for sym in [\"<start>\"] + list(item)])\n",
    "        y.append([sym2idx[sym] for sym in list(item) + [\"<end>\"]])\n",
    "        max_len = max(max_len, len(x[-1]))\n",
    "        if len(x) == batch_size or k + 1 == len(data):\n",
    "            for i in range(len(x)):\n",
    "                x[i] = x[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(x[i]))]\n",
    "                y[i] = y[i] + [sym2idx[\"<empty>\"] for _ in range(max_len - len(y[i]))]\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "            yield x, y\n",
    "            x, y, max_len = [], [], 0\n",
    "        \n",
    "\n",
    "def train_epoch(data, model):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    total_loss, total_count = 0.0, 1e-38\n",
    "    random.shuffle(data)\n",
    "    for inputs, answers in iterate_batches(data, batch_size, device):\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs.shape)\n",
    "        #print(answers.shape)\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.shape)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "        #print(outputs.shape)\n",
    "        #print(\"\")\n",
    "        loss = loss_function(outputs, answers)\n",
    "        total_loss += (loss.item() * inputs.shape[0])\n",
    "        total_count += inputs.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def test_epoch(data, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        total_loss, total_count = 0.0, 1e-38\n",
    "        for inputs, answers in iterate_batches(data, batch_size, device):\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.transpose(1, 2)\n",
    "            loss = loss_function(outputs, answers)\n",
    "            total_loss += (loss.item() * inputs.shape[0])\n",
    "            total_count += inputs.shape[0]\n",
    "        return total_loss / total_count\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for i in range(epoch_count):\n",
    "    train_loss = train_epoch(train, model)\n",
    "    test_loss = test_epoch(test, model)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Epoch {} loss: {:.5f} {:.5f}\".format(i, train_loss, test_loss))\n",
    "    print(generate(model, max_seq_len))\n",
    "    print(\"\")\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
